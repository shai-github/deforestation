{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKSvzcq9pSKS",
        "outputId": "2cc3db48-cebb-4dbc-f730-29202f75e38f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J5WWlQvNZSZ",
        "outputId": "2ec99325-6404-4809-dd35-68571cf25acb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikeras\n",
            "  Downloading scikeras-0.8.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: packaging<22.0,>=0.21 in /usr/local/lib/python3.7/dist-packages (from scikeras) (21.3)\n",
            "Requirement already satisfied: importlib-metadata>=3 in /usr/local/lib/python3.7/dist-packages (from scikeras) (4.11.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikeras) (1.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3->scikeras) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3->scikeras) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging<22.0,>=0.21->scikeras) (3.0.9)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.1.0)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.8.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.7/dist-packages (2.12.0)\n",
            "Collecting dask\n",
            "  Downloading dask-2022.2.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 15.0 MB/s \n",
            "\u001b[?25hCollecting dask_ml\n",
            "  Downloading dask_ml-2022.1.22-py3-none-any.whl (148 kB)\n",
            "\u001b[K     |████████████████████████████████| 148 kB 63.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: distributed in /usr/local/lib/python3.7/dist-packages (1.25.3)\n",
            "Collecting distributed\n",
            "  Downloading distributed-2022.2.0-py3-none-any.whl (837 kB)\n",
            "\u001b[K     |████████████████████████████████| 837 kB 53.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask) (0.11.2)\n",
            "Collecting pyyaml>=5.3.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 62.9 MB/s \n",
            "\u001b[?25hCollecting partd>=0.3.10\n",
            "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from dask) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from dask) (21.3)\n",
            "Collecting fsspec>=0.6.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 68.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->dask) (3.0.9)\n",
            "Collecting locket\n",
            "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Collecting multipledispatch>=0.4.9\n",
            "  Downloading multipledispatch-0.6.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from dask_ml) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from dask_ml) (1.3.5)\n",
            "Collecting dask-glm>=0.2.0\n",
            "  Downloading dask_glm-0.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from dask_ml) (1.21.6)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.7/dist-packages (from dask_ml) (0.51.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from dask_ml) (1.0.2)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed) (5.4.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed) (57.4.0)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed) (1.7.0)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed) (2.2.0)\n",
            "Requirement already satisfied: tornado>=5 in /usr/local/lib/python3.7/dist-packages (from distributed) (5.1.1)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed) (1.0.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from distributed) (2.11.3)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed) (7.1.2)\n",
            "Collecting cloudpickle>=1.1.1\n",
            "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from multipledispatch>=0.4.9->dask_ml) (1.15.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.51.0->dask_ml) (0.34.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.2->dask_ml) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.2->dask_ml) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->dask_ml) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->dask_ml) (1.1.0)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->distributed) (2.0.1)\n",
            "Installing collected packages: locket, pyyaml, partd, fsspec, cloudpickle, dask, multipledispatch, distributed, dask-glm, dask-ml\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2.12.0\n",
            "    Uninstalling dask-2.12.0:\n",
            "      Successfully uninstalled dask-2.12.0\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.1.0 which is incompatible.\u001b[0m\n",
            "Successfully installed cloudpickle-2.1.0 dask-2022.2.0 dask-glm-0.2.0 dask-ml-2022.1.22 distributed-2022.2.0 fsspec-2022.5.0 locket-1.0.0 multipledispatch-0.6.0 partd-1.2.0 pyyaml-6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikeras\n",
        "!pip install --upgrade dask dask_ml distributed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vn3gsUXxpbvr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import imageio\n",
        "import distributed\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import dask\n",
        "import dask.array as da\n",
        "from dask.distributed import Client\n",
        "\n",
        "# Initialize the Dask client\n",
        "client = Client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LwisBqCapjhd"
      },
      "outputs": [],
      "source": [
        "# Read in data\n",
        "\n",
        "tif_lst = os.listdir('/content/gdrive/MyDrive/tif_data/2021')\n",
        "\n",
        "array_lst = []\n",
        "for year in os.listdir('/content/gdrive/MyDrive/tif_data'):\n",
        "    if year != '.DS_Store':\n",
        "        lazy_raster_lst = [dask.delayed(imageio.imread)('/content/gdrive/MyDrive/tif_data/' + year + '/' + tif) for tif in tif_lst]\n",
        "        raster_lst = [da.from_delayed(lazy_raster, shape=(40,40), dtype='int32') for lazy_raster in lazy_raster_lst]\n",
        "        raster_array = da.stack(raster_lst, axis=0)\n",
        "        array_lst.append(raster_array)\n",
        "    raw_dataset = da.stack(array_lst, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AaEoxTalyckk"
      },
      "outputs": [],
      "source": [
        "# One-hot encode the data\n",
        "\n",
        "# This expands the number of channels for each raster from one to three\n",
        "\n",
        "# The first channel is equal to 1 if data is missing, 0 otherwise\n",
        "# The second channel is equal to 1 if no deforestation occurred, 0 otherwise\n",
        "# The third channel is equal to 1 if deforestation occurred, 0 otherwise\n",
        "\n",
        "dataset = (da.array([-1, 0, 1]) == da.stack([raw_dataset], axis=-1)).astype('int32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ss9lWuOhLgVU",
        "outputId": "f7605c48-daeb-4c9a-e543-3bbd4b860f83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset size: (20, 18, 40, 40, 3)\n",
            "Number of rasters per year: 20\n",
            "Number of years: 18\n",
            "Raster size: (40, 40, 3)\n"
          ]
        }
      ],
      "source": [
        "# Get the size of the dataset\n",
        "\n",
        "print('Dataset size:', dataset.shape)\n",
        "\n",
        "num_samples = dataset.shape[0]\n",
        "print('Number of rasters per year:', num_samples)\n",
        "\n",
        "num_frames = dataset.shape[1]\n",
        "print('Number of years:', num_frames)\n",
        "\n",
        "raster_size = dataset.shape[2:]\n",
        "print('Raster size:', raster_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHxYLR4ODfFQ",
        "outputId": "2f2d704f-0332-4386-dd95-451e14a13781"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "<class 'int'>\n"
          ]
        }
      ],
      "source": [
        "# Define the distribution strategy\n",
        "strategy = tf.distribute.MirroredStrategy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3ai8YMMApwzO"
      },
      "outputs": [],
      "source": [
        "# Split into train and test sets (use indexing to optimize memory)\n",
        "train_prop = 0.9\n",
        "sample_indices = da.arange(dataset.shape[0])\n",
        "da.random.seed(123)\n",
        "da.random.permutation(sample_indices)\n",
        "train_indices = sample_indices[:int(train_prop * dataset.shape[0])]\n",
        "test_indices = sample_indices[int(train_prop * dataset.shape[0]):]\n",
        "train_dataset = dataset[train_indices]\n",
        "test_dataset = dataset[test_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uNyqzqWmLsZf"
      },
      "outputs": [],
      "source": [
        "# Extract features and outcome variable\n",
        "# x is frames 0 to n-1, and y is frames 1 to n\n",
        "\n",
        "def split_x_y(data):\n",
        "    x = data[:, 0:data.shape[1]-1, :, :]\n",
        "    y = data[:, 1:data.shape[1], :, :]\n",
        "    return x, y\n",
        "\n",
        "x_train, y_train = split_x_y(train_dataset)\n",
        "x_test, y_test = split_x_y(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHCAdhMfqYoJ",
        "outputId": "6906531f-5aba-4a5d-c43f-f98456bb31d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Feature Shape: (18, 17, 40, 40, 3), Training Outcome Shape: (18, 17, 40, 40, 3)\n",
            "Testing Feature Shape: (2, 17, 40, 40, 3), Testing Outcome Shape: (2, 17, 40, 40, 3)\n"
          ]
        }
      ],
      "source": [
        "# Get the size of the training and test sets\n",
        "\n",
        "print(\"Training Feature Shape: \" + str(x_train.shape) + \n",
        "      \", Training Outcome Shape: \" + str(y_train.shape))\n",
        "print(\"Testing Feature Shape: \" + str(x_test.shape) + \n",
        "      \", Testing Outcome Shape: \" + str(y_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "HOcbCmzlqc9l"
      },
      "outputs": [],
      "source": [
        "# Define hyperparameters (we can cross-validate these later)\n",
        "\n",
        "epochs = 50\n",
        "BATCH_SIZE_PER_REPLICA = 8\n",
        "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
        "num_filters = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKbBJWSnN44W",
        "outputId": "0ba69afa-c771-42d9-c777-047f8b80caf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'int'>\n"
          ]
        }
      ],
      "source": [
        "print(type(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2vLnrTnB5Mk",
        "outputId": "d4da6d38-f04f-483a-92eb-66c8aca14fd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "  # Define the CNN-LSTM architecture\n",
        "\n",
        "  inp = layers.Input(shape=(None, *x_train.shape[2:]))\n",
        "\n",
        "  # Construct three ConvLSTM2D layers with batch norm,\n",
        "  # followed by a Conv3D layer so that the output is\n",
        "  # the same shape as the original raster\n",
        "  x = layers.ConvLSTM2D(filters=num_filters,\n",
        "                        kernel_size=(5, 5),\n",
        "                        padding=\"same\",\n",
        "                        return_sequences=True,\n",
        "                        activation=\"relu\",)(inp)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.ConvLSTM2D(filters=num_filters,\n",
        "                        kernel_size=(3, 3),\n",
        "                        padding=\"same\",\n",
        "                        return_sequences=True,\n",
        "                        activation=\"relu\",)(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.ConvLSTM2D(filters=num_filters,\n",
        "                        kernel_size=(1, 1),\n",
        "                        padding=\"same\",\n",
        "                        return_sequences=True,\n",
        "                        activation=\"relu\",)(x)\n",
        "  x = layers.Conv3D(filters=3, \n",
        "                    kernel_size=(3, 3, 3), \n",
        "                    activation=\"softmax\", \n",
        "                    padding=\"same\")(x)\n",
        "\n",
        "  # Build and compile the model\n",
        "  model = keras.models.Model(inp, x)\n",
        "  model.compile(loss=keras.losses.binary_crossentropy,\n",
        "                optimizer=keras.optimizers.Adam())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwTAXVakqwoj",
        "outputId": "48921fa5-4fe9-4190-8631-30f297c79a5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
            "Epoch 1/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.6058WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
            "3/3 [==============================] - 31s 8s/step - loss: 0.6058 - val_loss: 0.6777 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.1460 - val_loss: 0.6523 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.0495 - val_loss: 0.6227 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.0373 - val_loss: 0.5960 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.0324 - val_loss: 0.5650 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 15s 7s/step - loss: 0.0311 - val_loss: 0.5002 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.0320 - val_loss: 0.4439 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 10s 5s/step - loss: 0.0300 - val_loss: 0.4453 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.0290 - val_loss: 0.4197 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 11s 5s/step - loss: 0.0283 - val_loss: 0.4302 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 16s 7s/step - loss: 0.0277 - val_loss: 0.4157 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 11s 5s/step - loss: 0.0272 - val_loss: 0.3995 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 14s 7s/step - loss: 0.0269 - val_loss: 0.3850 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 9s 4s/step - loss: 0.0268 - val_loss: 0.3854 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.0274 - val_loss: 0.3796 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 13s 6s/step - loss: 0.0262 - val_loss: 0.3287 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.0263 - val_loss: 0.3295 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 9s 4s/step - loss: 0.0256 - val_loss: 0.3299 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 11s 5s/step - loss: 0.0252 - val_loss: 0.3226 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 14s 6s/step - loss: 0.0246 - val_loss: 0.3152 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 11s 5s/step - loss: 0.0244 - val_loss: 0.2947 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 11s 5s/step - loss: 0.0230 - val_loss: 0.2774 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.0219 - val_loss: 0.2670 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 10s 5s/step - loss: 0.0209 - val_loss: 0.2558 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 11s 5s/step - loss: 0.0195 - val_loss: 0.2527 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 11s 5s/step - loss: 0.0173 - val_loss: 0.2472 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 10s 5s/step - loss: 0.0149 - val_loss: 0.2387 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 11s 5s/step - loss: 0.0142 - val_loss: 0.2289 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 11s 5s/step - loss: 0.0126 - val_loss: 0.2201 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.0122 - val_loss: 0.2111 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 10s 5s/step - loss: 0.0114 - val_loss: 0.2036 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 11s 5s/step - loss: 0.0114 - val_loss: 0.1980 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 11s 5s/step - loss: 0.0104 - val_loss: 0.1976 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 11s 5s/step - loss: 0.0101 - val_loss: 0.1941 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 11s 5s/step - loss: 0.0100 - val_loss: 0.1889 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 11s 5s/step - loss: 0.0091 - val_loss: 0.1840 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 11s 5s/step - loss: 0.0088 - val_loss: 0.1809 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 14s 7s/step - loss: 0.0080 - val_loss: 0.1755 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 14s 6s/step - loss: 0.0080 - val_loss: 0.1669 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 14s 7s/step - loss: 0.0074 - val_loss: 0.1606 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 11s 5s/step - loss: 0.0070 - val_loss: 0.1540 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 14s 6s/step - loss: 0.0069 - val_loss: 0.1481 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 12s 5s/step - loss: 0.0064 - val_loss: 0.1412 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 11s 5s/step - loss: 0.0062 - val_loss: 0.1358 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 13s 6s/step - loss: 0.0059 - val_loss: 0.1300 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 11s 5s/step - loss: 0.0057 - val_loss: 0.1243 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.0057 - val_loss: 0.1158 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.0060 - val_loss: 0.1138 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 9s 4s/step - loss: 0.0057 - val_loss: 0.1080 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 11s 5s/step - loss: 0.0049 - val_loss: 0.1004 - lr: 0.0010\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbd1d508d50>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "\n",
        "# Define callbacks to improve training\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5)\n",
        "\n",
        "# Fit the model to the training data\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[early_stopping, reduce_lr],)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "SHlhCZD0rFO5",
        "outputId": "d8346864-6666-4c44-9714-5e98231f9759"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
            "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
            "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
            "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
            "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
            "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
            "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
            "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
            "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1440x288 with 18 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize results\n",
        "\n",
        "import numpy as np # the model returns a prediction as a numpy array\n",
        "\n",
        "# Select a single, random raster from the test set\n",
        "example = test_dataset[da.random.choice(range(len(test_dataset)), size=1)[0]]\n",
        "\n",
        "# Split the frames into two parts\n",
        "idx = example.shape[0] // 2\n",
        "frames = example[:idx, ...]\n",
        "original_frames = example[idx:, ...]\n",
        "\n",
        "# Predict a new set of frames\n",
        "for _ in range(idx):\n",
        "    # Extract the model's prediction and post-process it.\n",
        "    new_prediction_probs = model.predict(da.stack([frames], axis=0))\n",
        "    new_prediction_probs = np.squeeze(new_prediction_probs, axis=0)\n",
        "    predicted_frame_probs = np.expand_dims(new_prediction_probs[-1, ...], axis=0)\n",
        "    predicted_frame = np.eye(predicted_frame_probs.shape[3]) \\\n",
        "      [predicted_frame_probs.argmax(axis=3)] # convert probablities to 0s and 1s\n",
        "    # Extend the set of prediction frames\n",
        "    frames = np.concatenate((frames, predicted_frame), axis=0)\n",
        "\n",
        "# Construct a figure to plot the original and predicted frames\n",
        "fig, axes = plt.subplots(2, idx, figsize=(20, 4))\n",
        "\n",
        "# Plot the original frames\n",
        "for i, ax in enumerate(axes[0]):\n",
        "    ax.imshow(da.squeeze(original_frames[i]).astype('float64'), cmap=\"gray\")\n",
        "    ax.set_yticks([])\n",
        "    ax.set_xticks([])\n",
        "    ax.set_title(f\"{2013 + i}\")\n",
        "    if i == (idx - 1):\n",
        "        legend = [Patch(facecolor='red', label='Missing'),\n",
        "                  Patch(facecolor='lime', label='Not Deforested'),\n",
        "                  Patch(facecolor='blue', label='Deforested')]\n",
        "        ax.legend(handles=legend, bbox_to_anchor=(2.5, 1), fontsize=12)\n",
        "    if i==0:\n",
        "        ax.set_ylabel(\"Actual\")\n",
        "\n",
        "# Plot the predicted frames\n",
        "new_frames = frames[idx:, ...]\n",
        "for i, ax in enumerate(axes[1]):\n",
        "    ax.imshow(np.squeeze(new_frames[i]), cmap=\"gray\")\n",
        "    ax.set_yticks([])\n",
        "    ax.set_xticks([])\n",
        "    if i==0:\n",
        "        ax.set_ylabel(\"Predicted\")\n",
        "\n",
        "# Display the figure\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "dask_keras_gpu.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
